<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Model Use Cases</title>

  <!-- Bootstrap 5 -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css"
        rel="stylesheet"
        integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH"
        crossorigin="anonymous">

  <style>
    body            { background:#1a1a1a; color:#e0e0e0; font-family:Arial, sans-serif; }
    h1              { color:#17a2b8; text-align:center; margin:2rem 0 2.5rem; }
    h2              { color:#f0ad4e; margin:2.5rem 0 1.25rem; }
    .model-card     { background:#2a2a2a; border:1px solid #3a3a3a; border-radius:8px;
                      padding:1.5rem; margin-bottom:1.5rem; cursor:pointer;
                      transition:transform .2s, box-shadow .2s; }
    .model-card:hover { transform:translateY(-5px);
                        box-shadow:0 4px 12px rgba(0,0,0,.35); }
    .model-card h3  { color:#17a2b8; margin-bottom:.5rem; }
    .model-card p   { margin:0.3rem 0; color:#b0b0b0; }
    @media (max-width:576px){
      .model-card  { padding:1rem; }
      h1           { font-size:1.5rem; }
      h2           { font-size:1.25rem; }
    }
  </style>
</head>

<body>
  <div class="container">
    <h1>AI Model Use Cases</h1>

    <!-- High-Performance -->
    <h2>High-Performance Models</h2>
    <div class="row">
      <div class="col-12 col-md-4">
        <div class="model-card" data-model="vicuna:13b">
          <h3>vicuna:13b</h3>
          <p><strong>Use Case:</strong> ShareGPT-trained LLaMA-1 variant; GPT-3.5 quality chat in 13 B params.</p>
        </div>
      </div>
      <div class="col-12 col-md-4">
        <div class="model-card" data-model="falcon2:11b">
          <h3>falcon2:11b</h3>
          <p><strong>Use Case:</strong> 11 B multilingual with 32 k contextâ€”fast, large-window generation.</p>
        </div>
      </div>
      <div class="col-12 col-md-4">
        <div class="model-card" data-model="falcon3:7b">
          <h3>falcon3:7b</h3>
          <p><strong>Use Case:</strong> 7 B third-gen Falcon with strong zero-shot reasoning.</p>
        </div>
      </div>
    </div>

    <!-- Mistral family -->
    <h2>Mistral Family</h2>
    <div class="row">
      <div class="col-12 col-md-4">
        <div class="model-card" data-model="mistral-nemo:latest">
          <h3>mistral-nemo:latest</h3>
          <p><strong>Use Case:</strong> 12 B, 128 k context; multilingual chat &amp; code.</p>
        </div>
      </div>
      <div class="col-12 col-md-4">
        <div class="model-card" data-model="mistral:latest">
          <h3>mistral:latest</h3>
          <p><strong>Use Case:</strong> 7 B model that beats Llama-2-13B on reasoning.</p>
        </div>
      </div>
      <div class="col-12 col-md-4">
        <div class="model-card" data-model="mistral-small3.2:24b">
          <h3>mistral-small3.2:24b</h3>
          <p><strong>Use Case:</strong> 24 B enterprise-ready chat &amp; tool use.</p>
        </div>
      </div>
    </div>

    <!-- LLaMA family -->
    <h2>LLaMA Family</h2>
    <div class="row">
      <div class="col-12 col-md-4">
        <div class="model-card" data-model="llama3.1:latest">
          <h3>llama3.1:latest</h3>
          <p><strong>Use Case:</strong> Flagship open-weights with enhanced tokenizer.</p>
        </div>
      </div>
      <div class="col-12 col-md-4">
        <div class="model-card" data-model="llama3:8b">
          <h3>llama3:8b</h3>
          <p><strong>Use Case:</strong> Efficient 8 B rivaling larger Llama-2s on QA &amp; coding.</p>
        </div>
      </div>
      <div class="col-12 col-md-4">
        <div class="model-card" data-model="llama2-uncensored:7b">
          <h3>llama2-uncensored:7b</h3>
          <p><strong>Use Case:</strong> Unfiltered creative generation &amp; experiments.</p>
        </div>
      </div>
    </div>

    <!-- DeepSeek family -->
    <h2>DeepSeek Family</h2>
    <div class="row">
      <div class="col-12 col-md-4">
        <div class="model-card" data-model="deepseek-coder:6.7b">
          <h3>deepseek-coder:6.7b</h3>
          <p><strong>Use Case:</strong> 2 T-token code model for completion &amp; docs.</p>
        </div>
      </div>
      <div class="col-12 col-md-4">
        <div class="model-card" data-model="DeepSeek-R1:14b">
          <h3>DeepSeek-R1:14b</h3>
          <p><strong>Use Case:</strong> 14 B RL-trained reasoning model.</p>
        </div>
      </div>
      <div class="col-12 col-md-4">
        <div class="model-card" data-model="DeepSeek-R1:8b">
          <h3>DeepSeek-R1:8b</h3>
          <p><strong>Use Case:</strong> Lightweight 8 B sibling for edge devices.</p>
        </div>
      </div>
    </div>

    <!-- Gemma -->
    <h2>Gemma Family</h2>
    <div class="row">
      <div class="col-12 col-md-6">
        <div class="model-card" data-model="gemma3:1b">
          <h3>gemma3:1b</h3>
          <p><strong>Use Case:</strong> On-device summarization &amp; Q&amp;A.</p>
        </div>
      </div>
      <div class="col-12 col-md-6">
        <div class="model-card" data-model="gemma2:9b">
          <h3>gemma2:9b</h3>
          <p><strong>Use Case:</strong> Balanced 9 B for general NLP workloads.</p>
        </div>
      </div>
    </div>

    <!-- Dolphin -->
    <h2>Dolphin Family</h2>
    <div class="row">
      <div class="col-12 col-md-6">
        <div class="model-card" data-model="dolphin-mistral:7b">
          <h3>dolphin-mistral:7b</h3>
          <p><strong>Use Case:</strong> Uncensored chat on Mistral 7B.</p>
        </div>
      </div>
      <div class="col-12 col-md-6">
        <div class="model-card" data-model="dolphin3:8b">
          <h3>dolphin3:8b</h3>
          <p><strong>Use Case:</strong> General-purpose local chat &amp; math.</p>
        </div>
      </div>
    </div>

    <!-- Specialized -->
    <h2>Specialized Models</h2>
    <div class="row">
      <div class="col-12 col-md-6">
        <div class="model-card" data-model="wizardlm-uncensored:13b">
          <h3>wizardlm-uncensored:13b</h3>
          <p><strong>Use Case:</strong> Brainstorming &amp; tutor-style interactions.</p>
        </div>
      </div>
      <div class="col-12 col-md-6">
        <div class="model-card" data-model="medllama2:7b">
          <h3>medllama2:7b</h3>
          <p><strong>Use Case:</strong> Clinical text understanding (non-diagnostic).</p>
        </div>
      </div>
      <div class="col-12 col-md-6">
        <div class="model-card" data-model="starcoder2:15b">
          <h3>starcoder2:15b</h3>
          <p><strong>Use Case:</strong> 15 B multilingual code completion &amp; reasoning.</p>
        </div>
      </div>
    </div>
  </div>

  <!-- Make cards open index.html?model=... -->
  <script>
    document.querySelectorAll('.model-card').forEach(card=>{
      card.addEventListener('click',()=>{
        const m = card.dataset.model;
        window.location.href = `index.html?model=${encodeURIComponent(m)}`;
      });
    });
  </script>

  <!-- Bootstrap JS bundle -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz"
          crossorigin="anonymous"></script>
</body>
</html>

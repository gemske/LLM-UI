<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Model Use Cases</title>
    <!-- Bootstrap 5 CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <style>
        body {
            background-color: #1a1a1a;
            color: #e0e0e0;
            font-family: 'Arial', sans-serif;
        }
        .container {
            padding: 2rem 0;
        }
        h1 {
            color: #17a2b8;
            text-align: center;
            margin-bottom: 2rem;
        }
        .model-card {
            background-color: #2a2a2a;
            border: 1px solid #3a3a3a;
            border-radius: 8px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        .model-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
        }
        .model-card h3 {
            color: #17a2b8;
            margin-bottom: 0.5rem;
        }
        .model-card p {
            margin: 0.3rem 0;
            color: #b0b0b0;
        }
        .model-card p strong {
            color: #e0e0e0;
        }
        @media (max-width: 576px) {
            .model-card {
                padding: 1rem;
            }
            h1 {
                font-size: 1.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>AI Model Use Cases</h1>
        <div class="row">
            <div class="col-12">
                <div class="model-card">
                    <h3>llama3:8b</h3>
                    <p><strong>ID:</strong> 365c0bd3c000</p>
                    <p><strong>Size:</strong> 4.7 GB</p>
                    <p><strong>Use Case:</strong> LLaMA3:8b offers strong general-purpose performance across a range of tasks including reasoning, summarization, and content generation. Ideal for developers building intelligent assistants, knowledge bots, or creative writing tools.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>gemma2:9b</h3>
                    <p><strong>ID:</strong> ff02c3702f32</p>
                    <p><strong>Size:</strong> 5.4 GB</p>
                    <p><strong>Use Case:</strong> Gemma2:9b is a versatile model for general-purpose NLP tasks, offering a balance of performance and efficiency. Suitable for applications like text classification, sentiment analysis, or content generation in resource-constrained environments.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>dolphin3:8b</h3>
                    <p><strong>ID:</strong> d5ab9ae8e1f2</p>
                    <p><strong>Size:</strong> 4.9 GB</p>
                    <p><strong>Use Case:</strong> Dolphin3:8b excels in conversational AI with a focus on user-friendly interactions. It’s suited for customer support chatbots, virtual assistants, or educational tools where clear, concise, and engaging responses are needed.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>dolphin3:8b_extendedmem</h3>
                    <p><strong>ID:</strong> a300eddd5b05</p>
                    <p><strong>Size:</strong> 4.9 GB</p>
                    <p><strong>Use Case:</strong> Dolphin3:8b_extendedmem enhances conversational AI with extended memory for longer, context-aware interactions. Ideal for advanced chatbots, virtual assistants, or educational platforms requiring sustained dialogue.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>medllama2:7b</h3>
                    <p><strong>ID:</strong> a53737ec0c72</p>
                    <p><strong>Size:</strong> 3.8 GB</p>
                    <p><strong>Use Case:</strong> MedLLaMA2:7b is specialized for medical and healthcare-related NLP tasks. It’s ideal for processing medical texts, answering health-related queries, or assisting in clinical research, ensuring accurate and context-aware responses.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>ALIENTELLIGENCE Models</h3>
                    <p><strong>IDs:</strong> 82818a8d80ba (businessadministrator), 32330b52b272 (computerhardwareengineer), 7cd89c0584eb (projectmanager), 4808cecf5433 (gamemasterroleplaying), 5c92c4bfe0dd (cyberaisecurity), 5a67af5744b8 (contentsummarizer), 03b742aeead8 (ai2ndbrain), b35c7a0ef105 (attorney2), 7ea1eb939a5d (whiterabbitv2), fb8f363c0edf (chiefaiofficer)</p>
                    <p><strong>Sizes:</strong> 4.7 GB (most models), 27 GB (chiefaiofficer)</p>
                    <p><strong>Use Case:</strong> ALIENTELLIGENCE models are specialized for professional and technical roles. Includes businessadministrator for business process automation, computerhardwareengineer for hardware design support, projectmanager for project planning, gamemasterroleplaying for interactive storytelling, cyberaisecurity for cybersecurity analysis, contentsummarizer for text summarization, ai2ndbrain for knowledge management, attorney2 for legal document processing, whiterabbitv2 for creative or experimental tasks, and chiefaiofficer for high-level AI strategy (note: chiefaiofficer is resource-intensive at 27 GB). Suitable for domain-specific applications but varies in resource requirements.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>gemma3:1b</h3>
                    <p><strong>ID:</strong> 8648f39daa8f</p>
                    <p><strong>Size:</strong> 815 MB</p>
                    <p><strong>Use Case:</strong> Gemma3:1b is an ultra-lightweight model designed for basic NLP tasks in highly resource-constrained environments. Ideal for edge devices or low-power applications, such as simple text classification, keyword extraction, or lightweight chatbots.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>gemma3:1b_extendedmem</h3>
                    <p><strong>ID:</strong> a25a89cc4022</p>
                    <p><strong>Size:</strong> 815 MB</p>
                    <p><strong>Use Case:</strong> Gemma3:1b_extendedmem is an ultra-lightweight model with extended memory for basic NLP tasks in resource-constrained environments. Suitable for edge devices, supporting simple text classification, keyword extraction, or lightweight chatbots with improved context retention.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>DeepSeek-R1 (8b, 14b)</h3>
                    <p><strong>IDs:</strong> 6995872bfe4c (8b), c333b7232bdb (14b)</p>
                    <p><strong>Sizes:</strong> 5.2 GB (8b), 9.0 GB (14b)</p>
                    <p><strong>Use Case:</strong> DeepSeek-R1 models are optimized for research-oriented tasks, excelling in natural language understanding and generation. The 8b model suits resource-constrained research for tasks like text summarization and question answering. The 14b model offers improved accuracy for complex tasks like multi-turn dialogues. Choose based on task complexity and resource availability.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>wizardlm-uncensored:13b</h3>
                    <p><strong>ID:</strong> 886a369d74fc</p>
                    <p><strong>Size:</strong> 7.4 GB</p>
                    <p><strong>Use Case:</strong> WizardLM-Uncensored:13b is designed for open-ended conversational tasks with minimal content restrictions. Perfect for creative writing, brainstorming, or applications requiring unfiltered, expressive dialogue, such as storytelling or role-playing chatbots.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>llama2-uncensored:7b</h3>
                    <p><strong>ID:</strong> 44040b922233</p>
                    <p><strong>Size:</strong> 3.8 GB</p>
                    <p><strong>Use Case:</strong> LLaMA2-Uncensored:7b is built for unrestricted text generation, making it suitable for creative applications like fiction writing, open-ended Q&A, or scenarios where minimal content moderation is desired.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>wizard:latest</h3>
                    <p><strong>ID:</strong> d69f2c7c876a</p>
                    <p><strong>Size:</strong> 7.4 GB</p>
                    <p><strong>Use Case:</strong> Wizard:latest is designed for open-ended conversational tasks, likely with minimal content restrictions. Suitable for creative writing, brainstorming, or expressive dialogue in applications like storytelling or role-playing chatbots.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>charlie:latest</h3>
                    <p><strong>ID:</strong> 9cda48e82834</p>
                    <p><strong>Size:</strong> 7.4 GB</p>
                    <p><strong>Use Case:</strong> Charlie:latest is a general-purpose model suitable for conversational and text generation tasks. Ideal for applications requiring moderate performance, such as chatbots or content creation, but less specialized than domain-specific models.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>celina:latest</h3>
                    <p><strong>ID:</strong> 56d35733ff4e</p>
                    <p><strong>Size:</strong> 3.8 GB</p>
                    <p><strong>Use Case:</strong> Celina:latest is a compact general-purpose model for basic NLP tasks. Suitable for text generation or simple conversational applications in resource-constrained environments, but lacks specific domain specialization.</p>
                </div>
            </div>
            <div class="col-12">
                <div class="model-card">
                    <h3>jackass:latest</h3>
                    <p><strong>ID:</strong> dc8a9e342811</p>
                    <p><strong>Size:</strong> 3.8 GB</p>
                    <p><strong>Use Case:</strong> Jackass:latest is likely an experimental or niche model for creative or unconventional text generation tasks. Suitable for specialized applications requiring unique outputs, but its utility is less clear compared to other models.</p>
                </div>
            </div>
        </div>
    </div>
    <!-- Bootstrap 5 JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
</body>
</html>
